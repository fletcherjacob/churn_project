{"cells":[{"cell_type":"markdown","id":"8cb16da0","metadata":{},"source":[]},{"cell_type":"code","execution_count":6,"id":"a3fea417","metadata":{"tags":[],"trusted":true},"outputs":[],"source":["%idle_timeout 120\n","%glue_version 4.0\n","%worker_type G.1X\n","%number_of_workers 2\n","\n","import boto3\n","import sys\n","from awsglue.dynamicframe import DynamicFrame\n","from awsglue.transforms import *\n","from awsglue.utils import getResolvedOptions\n","from awsglue.context import GlueContext\n","from awsglue.job import Job\n","from pyspark.context import SparkContext\n","from pyspark.sql.functions import *\n","from pyspark.sql import functions as F\n"]},{"cell_type":"code","execution_count":8,"id":"789fc113","metadata":{},"outputs":[],"source":["sc = SparkContext.getOrCreate()\n","glueContext = GlueContext(sc)\n","spark = glueContext.spark_session\n","job = Job(glueContext)"]},{"cell_type":"code","execution_count":9,"id":"88c9aadf","metadata":{},"outputs":[],"source":["def handle_missing_users(sdf: DataFrame, unique_users: DataFrame) -> DataFrame:\n","    \"\"\"\n","    Handle missing users in a PySpark DataFrame.\n","\n","    Parameters:\n","    - sdf (DataFrame): PySpark DataFrame representing user data. Should have columns 'userId' and 'featur_name'.\n","    - unique_users (DataFrame): PySpark DataFrame with unique user information.\n","\n","    Returns:\n","    - DataFrame: Updated PySpark DataFrame with filled missing users.\n","    \"\"\"\n","\n","    sdf_user_count = sdf.count()\n","\n","    unique_count = unique_users.count()\n","\n","    if sdf_user_count != unique_count:\n","        print(f\"Missing Values: {unique_count - sdf_user_count}\")\n","        missing_users = unique_users.select(\"userId\").subtract(sdf.select(\"userId\"))\n","        # Since the sdf is only two we rename the column based on sdf's second column\n","        missing_users_sdf = missing_users.withColumn(sdf.columns[1], lit(0))\n","        filled_missing_users = sdf.union(missing_users_sdf)\n","\n","        return filled_missing_users\n","    else:\n","        return sdf"]},{"cell_type":"code","execution_count":4,"id":"7a4db5b0","metadata":{"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# Optimize the data movement from pandas to Spark DataFrame and back\n","spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n","\n","# You can define a distributed Spark DataFrame, to read the data in a distributed way and be able to process large data\n","# Here it takes a bit of time because we ask it to infer schema, in practice could just let it set everything as string\n","# and handle the schema manually\n","sdf = spark.read.json(\"s3a://udacity-dsnd/sparkify/sparkify_event_data.json\")"]},{"cell_type":"code","execution_count":7,"id":"bc17f812-6f86-4740-b197-efdf2b6dfbac","metadata":{"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# since our focus is on users that are on the platform\n","clean_psdf = sdf.dropna(subset=\"userId\")\n","clean_psdf.createOrReplaceTempView(\"cleaned_user_log\")\n","\n","\n","unique_users = clean_psdf[[\"userId\"]].distinct()"]},{"cell_type":"markdown","id":"7a2d3986-5625-4361-9802-4372316589a6","metadata":{"tags":[]},"source":["## Build Features"]},{"cell_type":"markdown","id":"776167f0-5888-40ce-8c14-7ce8fededad2","metadata":{"tags":[]},"source":["### Song Counts"]},{"cell_type":"code","execution_count":8,"id":"ea90bf5c-c3a0-4624-8fd3-d88a53544aad","metadata":{"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["AssertionError: \n"]}],"source":["song_counts = (\n","    clean_psdf[[\"userId\", \"artist\"]].dropna(subset=\"artist\").groupBy(\"userId\").count()\n",")\n","song_counts = song_counts.withColumnRenamed(\"count\", \"song_counts\")\n","\n","song_counts = handle_missing_users(song_counts, unique_users)"]},{"cell_type":"markdown","id":"9fa0e01d-2b2e-4d49-a7ca-3c080fdd4942","metadata":{"tags":[]},"source":["### Distinct Artist\n"]},{"cell_type":"code","execution_count":null,"id":"842b787c-1dda-4891-bdc4-68dd2258171b","metadata":{},"outputs":[],"source":["distinct_artist = (\n","    clean_psdf.filter(clean_psdf[\"artist\"].isNotNull())\n","    .groupBy(\"userId\")\n","    .agg(F.countDistinct(\"artist\").alias(\"distinct_artist\"))\n",")\n","\n","distinct_artist = handle_missing_users(distinct_artist, unique_users)"]},{"cell_type":"markdown","id":"c0556468-403f-4610-98d6-680f03879fb6","metadata":{},"source":["### User Level"]},{"cell_type":"code","execution_count":null,"id":"2b92075f-e879-4ae0-b0c3-728121240826","metadata":{},"outputs":[],"source":["user_level = (\n","    clean_psdf[[\"userId\", \"level\", \"ts\"]]\n","    .orderBy(\"ts\", ascending=False)\n","    .dropDuplicates(subset=[\"userId\"])\n","    .select(\"userId\", \"level\")\n",")\n","\n","level_flag_udf = udf(lambda x: 1 if x == \"paid\" else 0, IntegerType())\n","\n","# one-hot encode\n","user_level = user_level.withColumn(\n","    \"level_flag\", level_flag_udf(user_level[\"level\"])\n",").select(\"userId\", \"level_flag\")\n","\n","user_level = handle_missing_users(user_level, unique_users)"]},{"cell_type":"markdown","id":"4fb36d25-8448-4a91-821f-3039388eddf5","metadata":{},"source":["### Positive App Usage"]},{"cell_type":"code","execution_count":null,"id":"18902313-7c33-47f1-bb0e-dae67f9823c7","metadata":{},"outputs":[],"source":["positive_usage_list = [\"Thumbs Up\", \"Thumbs Down\", \"Add Friend\", \"Add to playlist\"]\n","\n","positive_usage = (\n","    clean_psdf[[\"userId\", \"page\"]]\n","    .filter(col(\"page\").isin(positive_usage_list))\n","    .groupBy(\"userId\")\n","    .count()\n",")\n","\n","positive_usage = positive_usage.withColumnRenamed(\"count\", \"pos_interactions\")\n","\n","positive_usage = handle_missing_users(positive_usage, unique_users)"]},{"cell_type":"markdown","id":"f26c6a38-7863-4dbd-8cf5-0323481b5ef1","metadata":{},"source":["### Negative Interactions"]},{"cell_type":"code","execution_count":null,"id":"db40ce5a-06ef-4a1f-a0cc-a61393aa4d28","metadata":{},"outputs":[],"source":["neg_interactions_list = [\"Error\", \"Help\"]\n","\n","neg_interactions = (\n","    clean_psdf[[\"userId\", \"page\"]]\n","    .filter(col(\"page\").isin(neg_interactions_list))\n","    .groupBy(\"userId\")\n","    .count()\n",")\n","\n","neg_interactions = neg_interactions.withColumnRenamed(\"count\", \"neg_interactions\")\n","\n","\n","neg_interactions = handle_missing_users(neg_interactions, unique_users)"]},{"cell_type":"markdown","id":"d6121604-2ad3-40ea-9db8-61a87154cec1","metadata":{},"source":["### Unique Locations"]},{"cell_type":"code","execution_count":null,"id":"e410ef4c-e436-442d-8511-bdd38d660ca9","metadata":{},"outputs":[],"source":["unique_locations = (\n","    clean_psdf.filter(clean_psdf[\"location\"].isNotNull())\n","    .groupBy(\"userId\")\n","    .agg(F.countDistinct(\"location\").alias(\"unique_locations\"))\n",")\n","\n","\n","unique_locations = handle_missing_users(unique_locations, unique_users)"]},{"cell_type":"markdown","id":"c1949a53-4b43-407f-b9b8-049f4017f86d","metadata":{},"source":["### Page Counts"]},{"cell_type":"code","execution_count":null,"id":"c278a74b-d4fa-4f1c-a315-a1339555f417","metadata":{},"outputs":[],"source":["# page_filter = [\"Cancel\", \"Cancellation Confirmation\", \"NextSong\"]\n","# page_count_df = (\n","#     clean_sdf[[\"userId\", \"page\"]]\n","#     .filter(~col(\"page\").isin(page_filter))\n","#     .toPandas()\n","#     .groupby(\"userId\")\n","#     .value_counts()\n","#     .reset_index()\n","#     .pivot(columns=\"page\", values=\"count\", index=\"userId\")\n","#     .fillna(int(0))\n","# )\n","\n","\n","# page_count_corr = page_count_df.corr()\n","\n","# sns.heatmap(\n","#     page_count_corr,\n","#     annot=False,\n","#     cmap=\"coolwarm\",\n","#     fmt=\".2f\",\n","#     linewidths=0.5,\n","# )\n","\n","# page_count = spark.createDataFrame(page_count_df.reset_index())"]},{"cell_type":"markdown","id":"3bc3518a-9a29-45be-97a1-19511dba53ae","metadata":{},"source":["### Label"]},{"cell_type":"code","execution_count":null,"id":"a5eb4a9a-c341-44ea-a510-c2db310caa0f","metadata":{},"outputs":[],"source":["labels = clean_psdf[[\"userId\", \"page\"]].filter(\n","    col(\"page\").isin([\"Cancellation Confirmation\", \"Cancel\"])\n",").drop_duplicates(['userId'])\n","\n","\n","labels = labels.withColumn('label', lit(1))\n","labels_df = labels.drop('page')\n","\n","labels_df = handle_missing_users(labels_df,unique_users)"]},{"cell_type":"markdown","id":"7e6316b8","metadata":{},"source":["### Combine Features"]},{"cell_type":"code","execution_count":null,"id":"b3436bf8","metadata":{},"outputs":[],"source":["dfs = [\n","    song_counts,\n","    song_listened_mean,\n","    user_level,\n","    positive_usage,\n","    neg_interactions,\n","    unique_locations,\n","    distinct_artist,\n","    # page_count,\n","]\n","\n","joined_features = labels_df\n","for df in dfs:\n","    joined_features = joined_features.join(df, \"userId\", \"outer\")"]},{"cell_type":"markdown","id":"651e53ca-f7ca-4bbf-9e4d-0cf3f22a1f45","metadata":{},"source":["### Export Features For Model Testing"]},{"cell_type":"code","execution_count":null,"id":"fc30ff96-3ba1-40b8-845b-e60084d98498","metadata":{},"outputs":[],"source":["\n","joined_features.dropDuplicates().drop(\"userId\").write\\\n","    .format(\"csv\")\\\n","    .option(\"quote\", None)\\\n","    .mode(\"append\")\\\n","    .save(\"s3://spark-spotify-data/cleaned_features\")"]}],"metadata":{"kernelspec":{"display_name":"sparkify_churn","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
