{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "\n",
    "\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"YourAppName\").getOrCreate()\n",
    "\n",
    "h2o.init()\n",
    "# Initialize H2OContext\n",
    "hc = H2OContext.getOrCreate()\n",
    "\n",
    "# Get H2OConf from H2OContext\n",
    "h2o_conf = hc.getConf()\n",
    "\n",
    "# Set H2OConf properties\n",
    "h2o_conf.set(\"spark.ext.h2o.client.language\", \"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_df = h2o.import_file(file_path)\n",
    "# h2o_df = spark.read.option(\"header\", True).csv(file_path)\n",
    "h2o_df = h2o_df.drop(\"userId\")\n",
    "\n",
    "try:\n",
    "    h2o_df.drop('C1')\n",
    "    h2o_df.drop('userId')\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "col_features = h2o_df.columns\n",
    "col_features.remove(\"label\")\n",
    "# Split the data into training and validation sets\n",
    "# Split the data into training and validation sets\n",
    "train, valid = h2o_df.split_frame(ratios=[0.85])\n",
    "\n",
    "# Define predictor and response columns\n",
    "predictor_cols = col_features\n",
    "response_col = \"label\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define hyperparameter grid\n",
    "hyperparams = {\n",
    "    'alpha': [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],  # Regularization parameter\n",
    "    'lambda': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize the linear regression model\n",
    "linear_reg = H2OGeneralizedLinearEstimator(family='binomial', link=\"logit\")\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = H2OGridSearch(linear_reg, hyperparams)\n",
    "grid_search.train(x=predictor_cols, y=response_col, training_frame=train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.get_grid()[0]\n",
    "\n",
    "# Make predictions on the validation set\n",
    "preds = best_model.predict(valid)\n",
    "\n",
    "# Get model performance on the validation set\n",
    "validation_performance = best_model.model_performance(valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(validation_performance.F1())\n",
    "print(validation_performance.F2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "h2o_df = h2o.import_file(file_path)\n",
    "# h2o_df = spark.read.option(\"header\", True).csv(file_path)\n",
    "h2o_df = h2o_df.drop(\"userId\")\n",
    "\n",
    "try:\n",
    "    h2o_df.drop('C1')\n",
    "    h2o_df.drop('userId')\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "col_features = h2o_df.columns\n",
    "col_features.remove(\"label\")\n",
    "# Split the data into training and validation sets\n",
    "# Split the data into training and validation sets\n",
    "train, valid = h2o_df.split_frame(ratios=[0.85])\n",
    "\n",
    "# Define predictor and response columns\n",
    "predictor_cols = col_features\n",
    "response_col = \"label\"\n",
    "\n",
    "\n",
    "# Define hyperparameter grid\n",
    "hyperparams = {\n",
    "    'learn_rate': [0.01, 0.1, 0.2],\n",
    "    'ntrees': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "\n",
    "gradient_boost = H2OGradientBoostingEstimator(seed=42)\n",
    "\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = H2OGridSearch(gradient_boost, hyperparams)\n",
    "grid_search.train(x=predictor_cols, y=response_col, training_frame=train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.get_grid()[0]\n",
    "\n",
    "# Make predictions on the validation set\n",
    "preds = best_model.predict(valid)\n",
    "\n",
    "# Get model performance on the validation set\n",
    "validation_performance = best_model.model_performance(valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
